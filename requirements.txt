<<<<<<< HEAD
# Core
numpy>=1.24,<3
scipy>=1.10
scikit-learn>=1.3
soundfile>=0.12

# ASR (Whisper CPU int8 via CTranslate2)
faster-whisper>=1.0
ctranslate2>=4.3

# DL stack (CPU)
torch>=2.0

# Diarization (ECAPA embeddings)
speechbrain>=0.5.16
=======
# Core math / audio
numpy>=1.24,<3
scipy>=1.10,<2
scikit-learn>=1.3,<2
soundfile>=0.12

# ASR (Whisper CPU int8 via CTranslate2)
faster-whisper>=1.0,<2
ctranslate2>=4.3,<5

# DL stack (CPU)
torch>=2.0,<3

# Speaker embeddings (ECAPA) for diarization
speechbrain>=0.5.16,<0.6

# Web UI
streamlit>=1.33,<2
>>>>>>> e9dca22 (Initial commit for transcribe (moved out of transcriber))
